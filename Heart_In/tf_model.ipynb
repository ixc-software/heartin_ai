{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import matplotlib\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "plt.style.use('ggplot')  # Красивые графики\n",
    "plt.rcParams['figure.figsize'] = (15, 5)  # Размер картинок\n",
    "df_data = pd.read_hdf('df_data.h5')\n",
    "\n",
    "\n",
    "from PIL import Image,ImageOps\n",
    "\n",
    "def image_ready(path:\"...\\\\image.PNG\" = \"String\", type:\" RGB or L\" = \"L\", size:\"pixel typle\" =(28,28)):\n",
    "\n",
    "    \"\"\"\"will return data in format network needs\"\"\"\n",
    "\n",
    "    image = Image.open(path).convert(type).resize(size)\n",
    "    inverted_image = ImageOps.invert(image)\n",
    "    matplotlib.pyplot.imshow(inverted_image, cmap='Greys', interpolation = 'None')\n",
    "\n",
    "    #маштабировать и сместить входные значения в пределах от 0.01 - 1.00  (любое значение в пределах 255 / 255.0 * 0.99) + 0.01)\n",
    "    return (np.asfarray(inverted_image.getdata())/ 255.0 * 0.99) + 0.01 # -> asfarray конвертирует массив в float\n",
    "    \n",
    "    \n",
    "#df_data['types'].value_counts() #- узнать количество типов\n",
    "#df_data['lengths'].mean() #- показать среднее значение\n",
    "df_data['types'].value_counts().plot.pie() #- нарисовать диаграмму\n",
    "\n",
    "def render(*array:\"lists of array\", frequency:'Hz'= 1, colors=['b', 'g', 'r', 'c', 'm', 'y', 'k', 'w']):\n",
    "    print(\"function 'render' in progress \\n\")\n",
    "    #возвращает цвета из массива colors, когда кончатся стандартные цвета, будет генерировать случайные\n",
    "    def get_color():\n",
    "        for color in colors:\n",
    "            yield color\n",
    "    #экземпляр класса get_color\n",
    "    color_buffer = get_color()\n",
    "\n",
    "    for n, y in enumerate(array):\n",
    "        #использует базовые цвета в наличии(colors), если заканчиваются, генерирует случайные\n",
    "        if n < len(colors):\n",
    "            color = next(color_buffer)        \n",
    "        else:\n",
    "            color = (np.random.randint(255, size=(1, 3))/255).flat\n",
    "\n",
    "        x  = np.linspace(0, frequency*len(y), len(y), endpoint=False)\n",
    "        plt.plot(x, y, color=color, marker ='')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Add ops to save and restore all the variables.\n",
    "# saver = tf.train.Saver()\n",
    "\n",
    "# save_path = saver.save(sess, r\"C:\\Users\\o.zaitsev\\Source\\Repos\\neuralNetwork\\Heart-In\\model.ckpt\")\n",
    "# print(\"Model saved in path: %s\" % save_path)\n",
    "\n",
    "#saver.restore(sess, r\"C:\\Users\\o.zaitsev\\Source\\Repos\\neuralNetwork\\Heart-In\\model.ckpt\")\n",
    "# print(\"Model restored.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#нормализовать данные normalize(data, axis=0, norm='max')\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "#исправляет данные Y, допустим [1,88,2334,1,88] исправит на [0, 1, 2, 0, 1]\n",
    "def y_renamer(array:\"dtype='int32'\", vector = False)->\"исправляет данные разметки\":\n",
    "    \n",
    "    df = pd.DataFrame(data= array, columns=[\"types\"])    \n",
    "    df_types = pd.DataFrame(data= df['types'].value_counts(), columns=[\"types\"])\n",
    "    \n",
    "    #что бы не подменило уже сущетв. номера \n",
    "    df.types = df.types +  max(df.types.value_counts().index)\n",
    "    \n",
    "    for type_number, i in enumerate(df.types.value_counts().index):         \n",
    "        df.types[df.types == i] = type_number\n",
    "        \n",
    "    if vector:\n",
    "        #[[0,0,0,1],[1,0,0,0]...]\n",
    "        df['vector'] = df.types.astype(str).str.get_dummies().values.tolist()\n",
    "\n",
    "        return np.array([np.array(i, dtype='float32') for i in df.vector])\n",
    "    else:\n",
    "        #[11,1,1,1,3,3,32,2,2,2...] \n",
    "        return df.get_values().reshape(-1)\n",
    "\n",
    "\n",
    "\n",
    "#сокращения\n",
    "x_data = df_data.systoles\n",
    "#типы\n",
    "y_true = y_renamer(df_data.types, vector = False)\n",
    "\n",
    "#разбить данные для обучения\n",
    "x_train, x_eval, y_train, y_eval = train_test_split(x_data,y_true,test_size=0.3, random_state = 101)\n",
    "\n",
    "\n",
    "x_train = np.array([np.array(i, dtype='float32') for i in x_train.get_values()])\n",
    "x_eval  = np.array([np.array(i, dtype='float32') for i in  x_eval.get_values()])\n",
    "\n",
    "y_train = np.array(y_train, dtype='int32')\n",
    "y_eval  = np.array(y_eval,  dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONVOLUTIONAL NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONVOLUTIONAL NEURAL NETWORK\n",
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "\n",
    "# Training Parameters\n",
    "learning_rate = 0.001\n",
    "num_steps = 10000\n",
    "batch_size = 128\n",
    "\n",
    "# Network Parameters\n",
    "num_input = 196 # systoles data input (img shape: 14*14)\n",
    "num_classes = 19 # systoles total classes (0-99 digits)\n",
    "dropout = 0.25 # Dropout, probability to drop a unit\n",
    "\n",
    "\n",
    "# Create the neural network\n",
    "def conv_net(x_dict, n_classes, dropout, reuse, is_training):\n",
    "    # Define a scope for reusing the variables\n",
    "    with tf.variable_scope('ConvNet', reuse=reuse):\n",
    "        # TF Estimator input is a dict, in case of multiple inputs\n",
    "        x = x_dict['images']\n",
    "\n",
    "        # systoles data input is a 1-D vector of 196 features (14*14 pixels)\n",
    "        # Reshape to match picture format [Height x Width x Channel]\n",
    "        # Tensor input become 4-D: [Batch Size, Height, Width, Channel]\n",
    "        x = tf.reshape(x, shape=[-1, 1, 196, 1])\n",
    "\n",
    "        # Convolution Layer with 16 filters and a kernel size of 4\n",
    "        conv1 = tf.layers.conv2d(x, filters=16, kernel_size= [1,4], activation=tf.nn.relu)\n",
    "        # Max Pooling (down-sampling) with strides of 2 and kernel size of 2\n",
    "        conv1 = tf.layers.max_pooling2d(conv1, pool_size=[1,2], strides = [1,2])\n",
    "\n",
    "        # Convolution Layer with 32 filters and a kernel size of 2\n",
    "        conv2 = tf.layers.conv2d(conv1, filters=32,  kernel_size= [1,2], activation=tf.nn.relu)\n",
    "        # Max Pooling (down-sampling) with strides of 2 and kernel size of 2\n",
    "        conv2 = tf.layers.max_pooling2d(conv2, pool_size=[1,2], strides = [1,2])\n",
    "\n",
    "        # Flatten the data to a 1-D vector for the fully connected layer\n",
    "        fc1 = tf.contrib.layers.flatten(conv2)\n",
    "\n",
    "        # Fully connected layer (in tf contrib folder for now)\n",
    "        fc1 = tf.layers.dense(inputs= fc1, units= 2048, activation=tf.nn.relu)\n",
    "        # Apply Dropout (if is_training is False, dropout is not applied)\n",
    "        fc1 = tf.layers.dropout(fc1, rate=dropout, training=is_training)\n",
    "\n",
    "        # Output layer, class prediction\n",
    "        out = tf.layers.dense(fc1, n_classes)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# Define the model function (following TF Estimator Template)\n",
    "def model_fn(features, labels, mode):\n",
    "    # Build the neural network\n",
    "    # Because Dropout have different behavior at training and prediction time, we\n",
    "    # need to create 2 distinct computation graphs that still share the same weights.\n",
    "    logits_train = conv_net(features, num_classes, dropout, reuse=False,\n",
    "                            is_training=True)\n",
    "    logits_test = conv_net(features, num_classes, dropout, reuse=True,\n",
    "                           is_training=False)\n",
    "\n",
    "    # Predictions\n",
    "    pred_classes = tf.argmax(logits_test, axis=1)\n",
    "    pred_probas = tf.nn.softmax(logits_test)\n",
    "\n",
    "    # If prediction mode, early return\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=pred_classes)\n",
    "\n",
    "        # Define loss and optimizer\n",
    "    loss_op = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        logits=logits_train, labels=tf.cast(labels, dtype=tf.int32)))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    train_op = optimizer.minimize(loss_op,\n",
    "                                  global_step=tf.train.get_global_step())\n",
    "\n",
    "    # Evaluate the accuracy of the model\n",
    "    acc_op = tf.metrics.accuracy(labels=labels, predictions=pred_classes)\n",
    "\n",
    "    # TF Estimators requires to return a EstimatorSpec, that specify\n",
    "    # the different ops for training, evaluating, ...\n",
    "    estim_specs = tf.estimator.EstimatorSpec(\n",
    "        mode=mode,\n",
    "        predictions=pred_classes,\n",
    "        loss=loss_op,\n",
    "        train_op=train_op,\n",
    "        eval_metric_ops={'accuracy': acc_op})\n",
    "\n",
    "    return estim_specs\n",
    "\n",
    "# Build the Estimator\n",
    "model = tf.estimator.Estimator(model_fn)\n",
    "\n",
    "# Define the input function for training\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(x={'images': x_train}, \n",
    "                                              y= y_train, \n",
    "                                              batch_size=batch_size, \n",
    "                                              num_epochs=None, \n",
    "                                              shuffle=True)\n",
    "# Train the Model\n",
    "model.train(input_fn, steps=num_steps)\n",
    "\n",
    "# Evaluate the Model\n",
    "# Define the input function for evaluating\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(x={'images': x_eval}, \n",
    "                                              y= y_eval, \n",
    "                                              batch_size=batch_size, \n",
    "                                              shuffle=False)\n",
    "# Use the Estimator 'evaluate' method\n",
    "\n",
    "e = model.evaluate(input_fn)\n",
    "\n",
    "print(\"Testing Accuracy:\", e['accuracy'])#95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import threading\n",
    "import logging\n",
    "from collections import Counter\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.WARNING) \n",
    "\n",
    "print(Counter(y_eval))\n",
    "for x, y in zip(x_eval, y_eval):\n",
    "    \n",
    "    if y != 3:\n",
    "        continue\n",
    "    input_fn = tf.estimator.inputs.numpy_input_fn(x={'images': np.array([x])}, batch_size=batch_size, shuffle=False, num_epochs=1)\n",
    "    # Use the Estimator 'evaluate' method\n",
    "    for p in model.predict(input_fn):\n",
    "        # Use the Estimator 'evaluate' method\n",
    "        #print('predict :', p, 'real :', y )  \n",
    "        if p == 3:\n",
    "            render(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
